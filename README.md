## License

A2UI is licensed under the Apache License, Version 2.0.

https://github.com/user-attachments/assets/1650891b-1ec3-4bc9-a7b3-b69bb9d57b3b


# A2UI: Agent-to-UI Runtime for Mobile  
**Human-in-the-loop execution for enterprise AI**

> _What if enterprise software stopped forcing humans to learn UIs ‚Äî  
and instead generated the right UI at the moment work happens?_

> **A2UI is a runtime for generating native mobile interfaces at runtime from AI agents - with humans in the loop and deterministic execution.**

AI agents are great at reasoning.  
They are terrible at responsibility.

Most AI-in-enterprise demos collapse the moment someone asks:

> *‚ÄúWhat happens when this writes to production?‚Äù*

A2UI takes a different approach.

Instead of letting agents mutate data directly, **agents generate task-specific native UIs**, humans confirm intent, and systems execute deterministically.

No chatbots.  
No RPA.  
No AI writing directly to SAP, Oracle, or Salesforce.

---

## Why A2UI Exists

Modern enterprises still run on systems like **SAP, Oracle, Salesforce**, and custom internal platforms.

These systems are:
- Desktop-first  
- Menu-heavy  
- Painful on mobile  
- Hostile to frontline workers  

As a result:
- Data entry is delayed or skipped  
- Records are incomplete or inaccurate  
- Compliance relies on memory instead of systems  
- Field teams actively avoid official software  

> The real problem isn‚Äôt data capture ‚Äî  
> **it‚Äôs forcing humans to navigate software instead of describing reality.**

---

## The Core Insight

Most enterprise work already looks like this:

1. Something happens in the real world  
2. A human understands what matters  
3. Software forces them through irrelevant UI  

**A2UI flips the model.**

Instead of:
> *‚ÄúFind the right screen and fill the form‚Äù*

We do:
> *‚ÄúDescribe what happened ‚Äî we‚Äôll generate the right UI‚Äù*

The UI becomes a **temporary artifact**, not a permanent product surface.

---

## What This Repo Demonstrates

This repository is an **iOS-first proof of concept** for **Agent-to-UI (A2UI)**.

It proves the hardest part:

> **Dynamic, native UI generation that enterprises can trust.**

Specifically, this repo includes:
- A SwiftUI runtime for rendering agent-generated UIs  
- A schema-driven mini-app system (not forms)  
- Local validation and deterministic execution  
- A demo app showing the full end-to-end flow  

This is **infrastructure**, not a vertical SaaS product.

---

## üé¨ 60-Second Demo

> Natural language ‚Üí generated native UI ‚Üí submit ‚Üí validated enterprise record

‚¨áÔ∏è *(Demo video goes here)*

---

## End-to-End Example: Warehouse Incident Reporting

A worker types (or speaks):

> **‚ÄúBroken pallet in aisle 4, leaking, urgent‚Äù**

That‚Äôs the only instruction.

### What happens next:

### 1Ô∏è‚É£ Task Inference  
An agent:
- Infers the task type (`warehouse_incident`)  
- Extracts signals (location, hazard, urgency)  
- Determines **what information is required**  

### 2Ô∏è‚É£ A2UI Generation  
A **native SwiftUI mini-app** is generated at runtime containing only:
- Photo (required)  
- Severity  
- Location (pre-filled)  
- Timestamp  
- Hazard toggle  
- Notes  

This UI **did not exist before the prompt** and will not exist afterward.

### 3Ô∏è‚É£ Human-in-the-Loop Confirmation  
- Defaults are pre-seeded  
- Required fields are validated  
- The human can correct the agent  

AI never submits data directly.

### 4Ô∏è‚É£ Deterministic Execution  
- A validated payload is produced  
- Written as a clean JSON record  
- Shaped for SAP / Oracle / middleware ingestion  

---

## Why This Is Not a Form Builder

| Traditional Forms | A2UI |
|------------------|------|
| Designed upfront | Generated at runtime |
| Generic | Task-specific |
| Menu-driven | Intent-driven |
| Static | Context-aware |
| UI-first | Reality-first |

This is **UI as a by-product of intent**, not a product artifact.

---

## Why Enterprises Can Trust This

The architecture enforces a hard boundary:

### ‚ùå AI does NOT
- Execute side effects  
- Write to systems  
- Skip validation  
- Persist records  

### ‚úÖ AI ONLY
- Infers intent  
- Proposes UI schemas  

### ‚úÖ Deterministic code
- Renders native UI  
- Validates required fields  
- Executes submissions  
- Produces records  

> **If the agent is wrong, the human corrects it before anything irreversible happens.**

---

## High-Level Architecture

```
Agent (LLM / Rules)
        ‚Üì
   UI Schema
        ‚Üì
 Native Mini-App (SwiftUI)
        ‚Üì
 Human Confirmation
        ‚Üì
 Deterministic Executor
        ‚Üì
 Enterprise System
```

AI proposes.  
Humans confirm.  
Systems execute.

---

## Why Mobile Is the Wedge

- Work happens at the edge (field, floor, bedside)  
- Mobile is where friction is highest  
- Legacy UIs do not translate to small screens  

iOS provides:
- Strong native controls  
- Offline capability  
- Secure sandboxing  
- Enterprise deployment paths  

This repo is iOS-first by design.

---

## Why Now

### 1Ô∏è‚É£ LLMs now understand intent, not just text  
### 2Ô∏è‚É£ Enterprises are drowning in UI debt  
### 3Ô∏è‚É£ Mobile is now the primary work surface  
### 4Ô∏è‚É£ Automation failed; augmentation is winning  
### 5Ô∏è‚É£ Open-source infrastructure is trusted again  

---

## One-Sentence Pitch

> **A2UI lets agents generate task-specific native mini-apps on demand, so frontline workers describe reality instead of navigating legacy software ‚Äî while enterprises still get clean, validated records.**

---

## License

Apache License, Version 2.0

---

## Interested?

We‚Äôre early and actively talking to **design partners**.

üëâ Open a GitHub Discussion  
üëâ Or email: vamshi.iitbhu@gmail.com




## üöÄ Getting Started: Add A2UI to Your iOS App

A2UI is distributed as a **Swift Package** and can be embedded into any iOS app in minutes.  
This section shows how to add A2UI, render a generated UI, and verify that everything works end-to-end.

---

### 1Ô∏è‚É£ Add A2UI via Swift Package Manager

In **Xcode**:

1. Open your iOS app project  
2. Go to **File ‚Üí Add Packages‚Ä¶**  
3. Enter the repository URL:

```
https://github.com/VamshiIITBHU14/A2UI
```

4. Select **Up to Next Major Version**  
5. Add the package to your **App target**

Once added, import the runtime:

```swift
import A2UIRuntime
```

---

### 2Ô∏è‚É£ Create the A2UI Engine

Initialize the engine once (for example, in your main view or app coordinator):

```swift
let engine = A2UIEngine()
```

This engine is responsible for:
- Inferring intent
- Generating UI schemas
- Executing tasks deterministically

---

### 3Ô∏è‚É£ Infer a Task from Natural Language

Call the agent with real-world input:

```swift
let intent = try engine.inferTask(
    input: "Broken pallet in aisle 4, leaking, urgent",
    context: TaskContext(
        userRole: "warehouse_worker",
        locationHint: "Aisle 4"
    )
)
```

This returns:
- A detected `taskType`
- Extracted signals (location, urgency, etc.)
- A **runtime-generated UI schema** (`UISchema`)

No UI is predefined.

---

### 4Ô∏è‚É£ Render the Generated Mini-App (Native UI)

Present the generated UI using SwiftUI:

```swift
NavigationLink {
    DynamicRendererView(schema: intent.uiSchema) { values in
        handleSubmit(values, intent)
    }
} label: {
    Text("Open Generated Mini-App")
}
```

The rendered UI is:
- 100% native SwiftUI
- Generated at runtime
- Task-specific (no generic forms)
- Human-in-the-loop by default

---

### 5Ô∏è‚É£ Execute the Task on Submit (Deterministic)

When the user taps **Submit**, execute the task:

```swift
let result = try engine.execute(
    taskType: intent.taskType,
    schema: intent.uiSchema,
    values: values,
    context: context
)
```

This step:
- Validates required fields
- Produces a structured payload
- Generates a reference ID
- Returns a deterministic execution result

‚ö†Ô∏è No AI is used at execution time.

---

### 6Ô∏è‚É£ What to Expect When Testing (Verification Checklist)

When running the demo app in Simulator or on device:

1. Enter a real-world description (e.g. incident, note, update)
2. Tap **Generate Mini-App**
3. Review the inferred task and extracted signals
4. Open the generated mini-app
5. Fill in required fields
6. Tap **Submit**
7. You are automatically returned to the Home screen
8. A success card appears showing:
   - Execution status
   - Reference ID
   - JSON payload preview

This confirms the full loop:

```
Intent ‚Üí UI ‚Üí Human ‚Üí Validation ‚Üí Record
```

---

### 7Ô∏è‚É£ Where Is the Data Stored?

In the demo app:
- The validated payload is written to the app‚Äôs **Documents directory**
- It is displayed back in the UI for inspection

In production:
- Replace the executor with:
  - SAP / Oracle APIs
  - Middleware services
  - Message queues
  - Offline sync pipelines

A2UI is backend-agnostic by design.

---

## üß† Important Design Notes

- This is **not** a form builder  
- This is **not** chat UI  
- This is **not** RPA  

A2UI generates **ephemeral, task-specific native interfaces** that exist only long enough to safely capture human-confirmed data.
